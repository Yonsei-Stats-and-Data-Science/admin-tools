# slurm.conf file generated by configurator easy.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ControlMachine=proxy
ControlAddr=192.168.10.6
# 
#MailProg=/bin/mail 
MpiDefault=none
#MpiParams=ports=#-# 
ProctrackType=proctrack/cgroup
ReturnToService=1
SlurmctldPidFile=/var/run/slurmctld.pid
#SlurmctldPort=6817 
SlurmdPidFile=/var/run/slurmd.pid
#SlurmdPort=6818 
SlurmdSpoolDir=/var/spool/slurmd
SlurmUser=slurm
#SlurmdUser=root 
StateSaveLocation=/var/spool
SwitchType=switch/none
TaskPlugin=task/none
# 
# 
# TIMERS 
KillWait=5 
MinJobAge=5
#SlurmctldTimeout=120 
SlurmdTimeout=15 
# 
# 
# SCHEDULING 
FastSchedule=1
SchedulerType=sched/backfill
SelectType=select/linear
#SelectTypeParameters=
# 
# 
# LOGGING AND ACCOUNTING 
AccountingStorageType=accounting_storage/none
#AccountingStorageLoc=/mnt/nas/admin/slurm_accounting/slurm_accounting.txt
ClusterName=chilipepper
#JobAcctGatherFrequency=30 
JobAcctGatherType=jobacct_gather/linux
SlurmctldDebug=3 
SlurmctldLogFile=/var/log/slurm/slurmcltd.log
SlurmdDebug=3 
SlurmdLogFile=/var/log/slurm/slurmd.log
# 
# 
# COMPUTE NODES 
GresTypes=gpu
NodeName=cpu-compute NodeAddr=192.168.10.7 CPUs=32 RealMemory=128916 Sockets=1 CoresPerSocket=32 ThreadsPerCore=1 State=UNKNOWN 
NodeName=gpu-compute Gres=gpu:graphics:2 NodeAddr=192.168.10.8 CPUs=16 RealMemory=80532 Sockets=1 CoresPerSocket=16 ThreadsPerCore=1 State=UNKNOWN 
PartitionName=all Nodes=ALL Default=YES MaxTime=INFINITE State=UP
